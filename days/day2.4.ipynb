{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b30a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LLM-Engineering\\llm-engineering\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import numpy as np\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from items import Item\n",
    "from testing import Tester\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2706985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "QUESTION = \"How much does this cost to the nearest dollar?\\n\\n\"\n",
    "DB = \"products_vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ce8741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Waiting for authentication in the web browser\n",
      "The web browser should have opened for you to authenticate and get an API \n",
      "token.\n",
      "If it didn't, please copy this URL into your web browser manually:\n",
      "\n",
      "⠙ Waiting for authentication in the web browser\n",
      "⠙ Waiting for authentication in the web browser\n",
      "https://modal.com/token-flow/tf-yFTqu3poCKutD18mPE2xtl\n",
      "\n",
      "⠙ Waiting for authentication in the web browser\n",
      "⠙ Waiting for authentication in the web browser\n",
      "\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠧ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠧ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠧ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠧ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠏ Waiting for token flow to complete...\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "⠼ Waiting for token flow to complete...\n",
      "⠴ Waiting for token flow to complete...\n",
      "⠦ Waiting for token flow to complete...\n",
      "⠧ Waiting for token flow to complete...\n",
      "⠇ Waiting for token flow to complete...\n",
      "⠋ Waiting for token flow to complete...\n",
      "⠙ Waiting for token flow to complete...\n",
      "⠹ Waiting for token flow to complete...\n",
      "⠸ Waiting for token flow to complete...\n",
      "\n",
      "Web authentication finished successfully!\n",
      "Token is connected to the marwanghobashy workspace.\n",
      "Verifying token against https://api.modal.com\n",
      "Token verified successfully!\n",
      "⠋ Storing token\n",
      "\n",
      "Token written to C:\\Users\\Marwa/.modal.toml in profile marwanghobashy.\n"
     ]
    }
   ],
   "source": [
    "!modal setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751ae359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6403c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Log in to HuggingFace\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d1490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another import after Logging in to Hugging Face - thank you Trung N.!\n",
    "\n",
    "from items import Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a52899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test pickle file:\n",
    "\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d87515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac76113",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "prices = [metadata['price'] for metadata in result['metadatas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cabc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest_model.pkl', 'rb') as f:\n",
    "    rf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb9b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.specialist_agent import SpecialistAgent\n",
    "from agents.frontier_agent import FrontierAgent\n",
    "from agents.random_forest_agent import RandomForestAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6610fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist = SpecialistAgent()\n",
    "frontier = FrontierAgent(collection)\n",
    "random_forest = RandomForestAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35726c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def description(item):\n",
    "    return item.prompt.split(\"to the nearest dollar?\\n\\n\")[1].split(\"\\n\\nPrice is $\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21775e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(item):\n",
    "    return random_forest.price(description(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1725addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'Samsung Galaxy S20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3739aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialist = SpecialistAgent()\n",
    "frontier = FrontierAgent(collection)\n",
    "random_forest = RandomForestAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73f3763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350.0\n",
      "432.91\n",
      "203.8251000000001\n"
     ]
    }
   ],
   "source": [
    "print(specialist.price(product))\n",
    "print(frontier.price(product))\n",
    "print(random_forest.price(product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab3e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [14:28<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "specialists = []\n",
    "frontiers = []\n",
    "random_forests = []\n",
    "prices = []\n",
    "for item in tqdm(test[1000:1250]):\n",
    "    text = description(item)\n",
    "    specialists.append(specialist.price(text))\n",
    "    frontiers.append(frontier.price(text))\n",
    "    random_forests.append(random_forest.price(text))\n",
    "    prices.append(item.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2657240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins = [min(s,f,r) for s,f,r in zip(specialists, frontiers, random_forests)]\n",
    "maxes = [max(s,f,r) for s,f,r in zip(specialists, frontiers, random_forests)]\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'Specialist': specialists,\n",
    "    'Frontier': frontiers,\n",
    "    'RandomForest': random_forests,\n",
    "    'Min': mins,\n",
    "    'Max': maxes,\n",
    "})\n",
    "\n",
    "# Convert y to a Series\n",
    "y = pd.Series(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "072239d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specialist: 0.41\n",
      "Frontier: 0.15\n",
      "RandomForest: -0.42\n",
      "Min: 0.44\n",
      "Max: 0.40\n",
      "Intercept=23.39\n"
     ]
    }
   ],
   "source": [
    "# Train a Linear Regression\n",
    "np.random.seed(42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "feature_columns = X.columns.tolist()\n",
    "\n",
    "for feature, coef in zip(feature_columns, lr.coef_):\n",
    "    print(f\"{feature}: {coef:.2f}\")\n",
    "print(f\"Intercept={lr.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed4f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(lr, 'ensemble_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57a71ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.ensemble_agent import EnsembleAgent\n",
    "ensemble = EnsembleAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e54171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408.30262321234045"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.price(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de8a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_pricer(item):\n",
    "    return max(0,ensemble.price(description(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea96d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bd782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
